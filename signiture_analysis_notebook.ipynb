{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%html\n",
    "# <style>div.input{display:none} div.output_stderr{display:none}</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[KnowEnG Signature_Analysis_Pipeline on Github](https://github.com/KnowEnG-Research/Signature_Analysis_Pipeline)\n",
    "\n",
    "# KnowEnG Signiture Analysis Notebook\n",
    "* context of developing the notebooks_KnowEnG repository.\n",
    "* running it on the notebooks.knoweng.org server.\n",
    "* with a common directory structure where all user notebooks call shared pipeline src.\n",
    "\n",
    "### Notebook widgets to set run parameters for Signiture Analysis Pipeline\n",
    "* define all run parameters.\n",
    "* define widget to set all run parameters.\n",
    "* define a function that takes a run_file and returns controls with a display controls function and a go button.\n",
    "\n",
    "### KnowEnG Pipelines; Yaml Files Translation: Run Relative Directory Replacements:\n",
    "* results_directory\n",
    "* run_directory, run_file (neither used in toolbox calls)\n",
    "* tmp_directory\n",
    "* /data/spreadsheets\n",
    "* /data/networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import base64\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.common import EmptyDataError\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "import traitlets\n",
    "\n",
    "from knpackage import toolbox as kn\n",
    "\n",
    "sys.path.insert(1, '../KnowEnG/Signature_Analysis_Pipeline/src')\n",
    "import gene_signature_toolbox as gst\n",
    "SPREADSHEETS_DIR = os.path.abspath('../KnowEnG/Signature_Analysis_Pipeline/data/spreadsheets')\n",
    "NETWORKS_DIR = os.path.abspath('../KnowEnG/Signature_Analysis_Pipeline/data/spreadsheets')\n",
    "YAML_DIR = os.path.abspath('../KnowEnG/Signature_Analysis_Pipeline/data/run_files')\n",
    "\n",
    "sys.path.insert(1, '../KnowEnG/notebooks_KnowEnG/src')\n",
    "from layout_notebooks import *\n",
    "\n",
    "from   lifelines import KaplanMeierFitter\n",
    "from   lifelines.statistics import logrank_test, multivariate_logrank_test, pairwise_logrank_test\n",
    "\n",
    "results_dir = USER_RESULTS_DIRECTORY\n",
    "input_data_dir = USER_DATA_DIRECTORY\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile os.path.join('../src', localize_run_parameters.py)\n",
    "# \"\"\"\n",
    "# author: lanier4@illinois.edu\n",
    "# functions to convert yaml file data source and output directory references \n",
    "# to local directory references using a python dict\n",
    "# \"\"\"\n",
    "# import os\n",
    "\n",
    "def yaml_append(yaml_file_name_full_path, new_key, new_value):\n",
    "    \"\"\" Usage:  yaml_append(yaml_file_name_full_path, new_key, new_value)  \"\"\"\n",
    "    if not os.path.isfile(yaml_file_name_full_path):\n",
    "        print('file not found:\\n', yaml_file_name_full_path)\n",
    "        return\n",
    "    \n",
    "    appendable_text = '\\n' + new_key + ':    ' + new_value + '\\n'\n",
    "    print(yaml_file_name_full_path)\n",
    "    try:\n",
    "        with open(yaml_file_name_full_path, \"a+\") as yaml_file:\n",
    "            yaml_file.write(appendable_text)\n",
    "    except:\n",
    "        print('Not Properly Appended:\\n', yaml_file_name_full_path)\n",
    "        pass\n",
    "\n",
    "def get_yaml_files_list(YAML_DIR):\n",
    "    \"\"\" yaml_files = get_yaml_files_list(YAML_DIR) \"\"\"\n",
    "    yaml_files = []\n",
    "    for f in os.listdir(YAML_DIR):\n",
    "        if os.path.isfile(os.path.join(YAML_DIR, f)) and f[-3:] == 'yml':\n",
    "            yaml_files.append(f)\n",
    "            \n",
    "    return yaml_files\n",
    "\n",
    "def display_yaml_files_list(YAML_DIR):\n",
    "    yaml_files = get_yaml_files_list(YAML_DIR)\n",
    "    print(YAML_DIR)\n",
    "    for f in yaml_files:\n",
    "        print('\\t',f)\n",
    "\n",
    "def display_all_yaml_files(YAML_DIR, yaml_files):\n",
    "    n_files = len(yaml_files)\n",
    "    count = 0\n",
    "    for f in yaml_files:\n",
    "        count += 1\n",
    "        print('\\n\\n%30s : %s'%(f, YAML_DIR))\n",
    "        print('%30s : %s '%(' \"file[' + str(count-1) + ']\" :~) ' + str(count), 'of ' + str(n_files)))\n",
    "        run_parameters = kn.get_run_parameters(YAML_DIR, f)\n",
    "        for k, v in run_parameters.items():\n",
    "            print('%30s : %s'%(k,v))\n",
    "\n",
    "def get_available_directory_names(DIR_NAME):\n",
    "    \"\"\" dir_names = get_available_directory_names(DIR_NAME) \"\"\"\n",
    "    if not os.path.isdir(DIR_NAME):\n",
    "        return []\n",
    "    dir_names = []\n",
    "    for maybe_dir in os.listdir(DIR_NAME):\n",
    "        if os.path.isdir(maybe_dir) and maybe_dir[0] != '.':\n",
    "            dir_names.append(maybe_dir)\n",
    "\n",
    "    return dir_names\n",
    "\n",
    "def set_local_run_parameters(run_parameters, local_dict):\n",
    "    \"\"\" run_parameters = set_local_run_parameters(run_parameters, local_dict) \"\"\"\n",
    "    for key_name, key_value in local_dict.items():\n",
    "        for k, v in run_parameters.items():\n",
    "            if 'full_path' in k or 'directory' in k:\n",
    "                if key_name in v:\n",
    "                    de_nada, f_name = os.path.split(v)\n",
    "                    run_parameters[k] = os.path.join(key_value, f_name)\n",
    "                \n",
    "    return run_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lanier4/git_clone/dlanier/KnowEnG/Signature_Analysis_Pipeline/data/run_files\n",
      "\t BENCHMARK_1_GS_cos.yml\n",
      "\t BENCHMARK_1_GS_spearman.yml\n",
      "\t BENCHMARK_2_GS_net_cos.yml\n",
      "\t BENCHMARK_2_GS_net_spearman.yml\n",
      "\t BENCHMARK_3_GS_cc_cos.yml\n",
      "\t BENCHMARK_3_GS_cc_spearman.yml\n",
      "\t BENCHMARK_4_GS_cc_net_cos.yml\n",
      "\t BENCHMARK_4_GS_cc_net_spearman.yml\n",
      "\t TEST_1_GS_cos.yml\n",
      "\t TEST_1_GS_spearman.yml\n",
      "\t TEST_2_GS_net_cos.yml\n",
      "\t TEST_2_GS_net_spearman.yml\n",
      "\t TEST_3_GS_cc_cos.yml\n",
      "\t TEST_3_GS_cc_spearman.yml\n",
      "\t TEST_4_GS_cc_net_cos.yml\n",
      "\t TEST_4_GS_cc_net_spearman.yml\n",
      "\t zTEMPLATE_cc_net_cos.yml\n",
      "\t zTEMPLATE_cc_net_spearman.yml\n"
     ]
    }
   ],
   "source": [
    "# yaml_files = get_yaml_files_list(YAML_DIR)\n",
    "# display_all_yaml_files(YAML_DIR, yaml_files)\n",
    "display_yaml_files_list(YAML_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST_1_GS_cos.yml\n",
      "\n",
      "            similarity_measure : cosine\n",
      "             results_directory : ./run_dir/results\n",
      "                        method : similarity\n",
      "                 run_directory : /Users/lanier4/git_clone/dlanier/KnowEnG/Signature_Analysis_Pipeline/data/run_files\n",
      "                      run_file : TEST_1_GS_cos.yml\n",
      "                 tmp_directory : ./run_dir/tmp\n",
      "      signature_name_full_path : ../data/spreadsheets/TEST_1_signature.tsv\n",
      "    spreadsheet_name_full_path : ../data/spreadsheets/TEST_1_gene_sample.tsv\n",
      "\n",
      "Available Directories:\n",
      "build\n",
      "data\n",
      "results\n",
      "src\n",
      "test\n",
      "user_data\n"
     ]
    }
   ],
   "source": [
    "run_file_name = 'TEST_1_GS_cos.yml'\n",
    "run_parameters = kn.get_run_parameters(YAML_DIR, run_file_name)\n",
    "print('\\t%s\\n'%run_file_name)\n",
    "for k, v in run_parameters.items():\n",
    "    print('%30s : %s'%(k,v))\n",
    "\n",
    "print('\\nAvailable Directories:')\n",
    "for d in os.listdir():\n",
    "    if os.path.isdir(d) and d[0] != '.':\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPREADSHEETS_DIR = os.path.abspath('../KnowEnG/Signature_Analysis_Pipeline/data/spreadsheets')\n",
    "NETWORKS_DIR = os.path.abspath('../KnowEnG/Signature_Analysis_Pipeline/data/spreadsheets')\n",
    "YAML_DIR = os.path.abspath('../KnowEnG/Signature_Analysis_Pipeline/data/run_files')\n",
    "run_dir = os.getcwd()\n",
    "local_dict = {'data/spreadsheets': SPREADSHEETS_DIR, \n",
    "              'data/networks': NETWORKS_DIR, \n",
    "              'run_dir' : run_dir, \n",
    "              'data/run_files' : YAML_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            similarity_measure : cosine\n",
      "              accuracy_measure : ../KnowEnG/Signature_Analysis_Pipeline/data/spreadsheets/label_validation.txt\n",
      "             results_directory : /Users/lanier4/git_clone/dlanier/notebooks_KnowEnG/results\n",
      "                        method : similarity\n",
      "                 run_directory : /Users/lanier4/git_clone/dlanier/KnowEnG/Signature_Analysis_Pipeline/data/run_files/run_files\n",
      "                      run_file : TEST_1_GS_cos.yml\n",
      "                 tmp_directory : /Users/lanier4/git_clone/dlanier/notebooks_KnowEnG/tmp\n",
      "      signature_name_full_path : /Users/lanier4/git_clone/dlanier/KnowEnG/Signature_Analysis_Pipeline/data/spreadsheets/TEST_1_signature.tsv\n",
      "    spreadsheet_name_full_path : /Users/lanier4/git_clone/dlanier/KnowEnG/Signature_Analysis_Pipeline/data/spreadsheets/TEST_1_gene_sample.tsv\n"
     ]
    }
   ],
   "source": [
    "run_parameters_lcl = set_local_run_parameters(run_parameters, local_dict)\n",
    "run_parameters_lcl['accuracy_measure'] = \\\n",
    "    '../KnowEnG/Signature_Analysis_Pipeline/data/spreadsheets/label_validation.txt'\n",
    "for k, v in run_parameters_lcl.items():\n",
    "    print('%30s : %s'%(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "     S1   S2\n",
      "E1  1.0  1.0\n",
      "E2  1.0  1.0\n",
      "E3  1.0  1.0\n",
      "E4  1.0  1.0\n",
      "<class 'pandas.core.series.Series'>\n",
      "E1    S1\n",
      "E2    S1\n",
      "E3    S1\n",
      "E4    S1\n",
      "dtype: object\n",
      "['S1' 'S1' 'S1' 'S1']\n"
     ]
    }
   ],
   "source": [
    "expression_name     = run_parameters_lcl[\"spreadsheet_name_full_path\"]\n",
    "signature_name      = run_parameters_lcl[\"signature_name_full_path\"  ]\n",
    "similarity_measure  = run_parameters_lcl[\"similarity_measure\"        ]\n",
    "accuracy_measure    = run_parameters_lcl[\"accuracy_measure\"        ]\n",
    "\n",
    "expression_df       = kn.get_spreadsheet_df(expression_name)\n",
    "signature_df        = kn.get_spreadsheet_df(signature_name )\n",
    "\n",
    "samples_names       = expression_df.columns\n",
    "signatures_names    =  signature_df.columns\n",
    "signatures_names    = [i.split('.')[0] for i in signatures_names]\n",
    "signature_df.columns= signatures_names\n",
    "\n",
    "similarity_mat = generate_similarity_mat(expression_df, signature_df,similarity_measure)\n",
    "# similarity_mat = map_similarity_range(similarity_mat, 0)\n",
    "similarity_df  = pd.DataFrame(similarity_mat, index=samples_names, columns=signatures_names)     # 37\n",
    "\n",
    "# print(similarity_mat)\n",
    "print('similarity_df\\n',similarity_df)\n",
    "result = similarity_df.idxmax(axis=1, skipna=True)\n",
    "# benchmark = pd.read_csv('../data/spreadsheets/label_validation.txt', index_col=None, header=None, sep='\\t')\n",
    "# accuracy = calculate_accuracy(similarity_df, accuracy_measure)\n",
    "# print(accuracy)\n",
    "# print(type(result))\n",
    "# print(result)\n",
    "# ret_li = result.values\n",
    "# print(ret_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from   sklearn.metrics.pairwise import cosine_similarity\n",
    "# from   scipy.stats              import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity_mat(expression_df, signature_df,similarity_measure):\n",
    "    \"\"\"generate matrix which save the similarity value of input dataframes\n",
    "\n",
    "    Args:\n",
    "        expression_df: genes x samples dataframe.\n",
    "        signature_df:  genes x samples dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        similarity_mat: matrix with similarity values\n",
    "    \"\"\"\n",
    "\n",
    "    genes_in_expression =  expression_df.index\n",
    "    genes_in_signature  =   signature_df.index\n",
    "\n",
    "    common_genes        = kn.find_common_node_names(genes_in_expression, genes_in_signature)\n",
    "    expression_mat      = expression_df.loc[common_genes, :].values\n",
    "    signature_mat       =  signature_df.loc[common_genes, :].values\n",
    "    nx                  = expression_mat.shape[1]\n",
    "\n",
    "    if   (similarity_measure == \"cosine\" ):\n",
    "          similarity_mat      = cosine_similarity(expression_mat.T, signature_mat.T)\n",
    "          # print(similarity_mat.shape)\n",
    "    elif (similarity_measure == \"spearman\"):\n",
    "          similarity_mat      = spearmanr(expression_mat, signature_mat)[0]\n",
    "          # print(expression_mat)\n",
    "          similarity_mat      = np.abs(similarity_mat[0:nx,nx:] )\n",
    "          # print(similarity_mat.shape)\n",
    "    return similarity_mat\n",
    "\n",
    "def run_similarity(run_parameters):\n",
    "    \"\"\" Performs similarity analysis and saves the similarity matrix.\n",
    "\n",
    "    Args:\n",
    "        run_parameters: parameter set dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    expression_name     = run_parameters[\"spreadsheet_name_full_path\"]\n",
    "    signature_name      = run_parameters[\"signature_name_full_path\"  ]\n",
    "    similarity_measure  = run_parameters[\"similarity_measure\"        ]\n",
    "    accuracy_measure    = run_parameters[\"accuracy_measure\"        ]\n",
    "\n",
    "    expression_df       = kn.get_spreadsheet_df(expression_name)\n",
    "    signature_df        = kn.get_spreadsheet_df(signature_name )\n",
    "    \n",
    "    samples_names       = expression_df.columns\n",
    "    signatures_names    =  signature_df.columns\n",
    "    signatures_names    = [i.split('.')[0] for i in signatures_names]\n",
    "    signature_df.columns= signatures_names\n",
    "\n",
    "    similarity_mat = generate_similarity_mat(expression_df, signature_df,similarity_measure)\n",
    "    # similarity_mat = map_similarity_range(similarity_mat, 0)\n",
    "    similarity_df  = pd.DataFrame(similarity_mat, index=samples_names, columns=signatures_names)     # 37\n",
    "    accuracy = calculate_accuracy(similarity_df, accuracy_measure)\n",
    "    print(accuracy)\n",
    "#     save_final_samples_signature(similarity_df, run_parameters)\n",
    "    \n",
    "def read_listfile(list_file_name):\n",
    "    \"\"\" pandas read a list from a file\n",
    "    Args:\n",
    "        list_file_name: full path name of a panda readable list file\n",
    "    \"\"\"\n",
    "    list_file_list = pd.read_csv(list_file_name, index_col=None, header=None, sep='\\t')\n",
    "    return list_file_list\n",
    "    \n",
    "def calculate_accuracy(similarity_df, list_file_name):\n",
    "    \"\"\" Calculate accuracy given similarity dataframe and benchmark result\n",
    "\n",
    "    Args:\n",
    "        similarity_df: result dataframe from run_similarity methods\n",
    "    \"\"\"\n",
    "    result = similarity_df.idxmax(axis=1, skipna=True)\n",
    "    # benchmark = read_listfile(list_file_name)\n",
    "    benchmark = pd.read_csv('../data/spreadsheets/label_validation.txt', index_col=None, header=None, sep='\\t')\n",
    "    ret_li = result.values\n",
    "    ben_li = benchmark.values.reshape((1,-1))[0]\n",
    "\n",
    "    # common = np.sum(np.int(ret_li==ben_li) + 0.0)\n",
    "    common = ret_li==ben_li\n",
    "    common[common==True] = 1\n",
    "    common[common==False] = 0\n",
    "    accuracy = sum(common)/len(ret_li)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
